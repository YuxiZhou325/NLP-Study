{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1>Decision Tree and Random Forest</h1>\n",
    "\n",
    "> Author: Yuxi Zhou\n",
    "> Start Date: 2022-05-12 18:46:08"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Decision Tree and Variants</h2>\n",
    "\n",
    "> Supervised Learning\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "- Divide the input space into different regions, each with independent parameters\n",
    "- Inductive instance based learning algorithm\n",
    "- Generate a tree-shaped model of classification out of a given unordered training sample\n",
    "- Each non-leaf node in the tree records which feature is used to make a category determination, and each leaf node represents the final category determined.\n",
    "- The root node to each leaf node forms a path rule for classification.\n",
    "- When testing a new sample, one simply starts at the root node, tests at each branch node, and recursively moves along the corresponding branch into the subtree and tests again until one reaches the leaf node, where the category represented by that leaf node is the predicted category of the current test sample."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Simpleness\n",
    "> Compared to other machine learning classification algorithms, decision tree classification algorithms are relatively simple and can be considered for construction **as long as the training sample set can be represented using feature vectors and categories**. The complexity of the predictive classification algorithm is only related to the **number of layers of the decision tree**, which is **linear**, and the data is processed efficiently, making it **suitable for real-time classification situations**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predictive Model\n",
    "\n",
    "> In machine learning, a decision tree is a predictive model. It represents a **mapping** relationship between object attributes and values. Each **node** in the tree represents an **object**, while each **branch path** represents a possible **attribute value**, and each **leaf node** corresponds to the value of the object represented by the path from the root node to that leaf node. Decision trees have only a **single output**, therefore, separate decision trees are needed to handle different outputs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training and Testing\n",
    "> **Training**: the set of training samples is **split into subsets using certain criteria and rules**, and then each subset is split with the **same rules**, recursively until each subset contains **only samples belonging to the same class**. During the training process, each segmentation node needs to save the **attribute number** of the classification.\n",
    ">\n",
    "> **Testing**: the test sample is **determined from the root node** to see which sub-node it belongs to, again **recursively until the sample is split into a leaf node**, at which point the sample belongs to the current leaf node's class.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<H3>Decision Tree Symbols</h3>\n",
    "\n",
    "| Shape                                                                                              | Name                 | Meaning                                            |\n",
    "|----------------------------------------------------------------------------------------------------|----------------------|----------------------------------------------------|\n",
    "| [<img src=\"images/decision_tree_symbols_01.png\" width=\"100\">](images/decision_tree_symbols_01.png) | Decision node        | Indicates a decision to be made                    |\n",
    "| [<img src=\"images/decision_tree_symbols_02.png\" width=\"100\">](images/decision_tree_symbols_02.png) | Chance node          | Shows multiple uncertain outcomes                  |\n",
    "| [<img src=\"images/decision_tree_symbols_04.png\" width=\"100\">](images/decision_tree_symbols_04.png) | Alternative branches | Each branch indicates a possible outcome or action |\n",
    "| [<img src=\"images/decision_tree_symbols_05.png\" width=\"100\">](images/decision_tree_symbols_05.png) | Rejected alternative | Shows a choice that was not selected               |\n",
    "| [<img src=\"images/decision_tree_symbols_03.png\" width=\"100\">](images/decision_tree_symbols_03.png) | Endpoint node        | Indicates a final outcome, class label             |"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Decision is a tree-shaped structure</h4>\n",
    "\n",
    "- Decision Node: represents an **intermediate process**, mainly used to **compare the values of individual attributes in a dataset to determine the trend of the next decision**\n",
    "- Chance Node (Status Node): represents the **expected value of the alternative**, and the **best result can be selected by comparing the various chance (state) nodes**\n",
    "- Result Node (Endpoint Node): represents **which class the class ultimately belongs to**, and it is also clear to see how many classes the model has in total. Finally, **a data instance gets its decision node based on the values taken for each attribute**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The decision tree is formed by extending the root node in sequence from top to bottom, extending everywhere up to the next **attribute node** based on the **variability of the attribute thresholds**, and extending all the way to the final leaf node to complete the prediction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instability\n",
    "\n",
    "> Due to the instability of the decision tree classification method, a small change in the sample set may lead to a large change in the structure of the decision tree **when the number of samples in the training sample set is small**. To improve the stability of decision tree classification, the **Bagging** technique can be used. Let the decision tree algorithm undergo **multiple rounds of training**, and use **voting for the category prediction of the test samples**.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Decision tree training in **statistics, data mining and machine learning** uses decision trees as a **predictive model** to predict the class labels of a sample.\n",
    "\n",
    "These decision trees are also called categorical or regression trees. In the structure of these trees, the **leaf nodes give class labels and the internal nodes represent an attribute**.\n",
    "\n",
    " Decision tree learning:\n",
    " Decision models are built using a tree structure **based on the attributes of the data**. Decision tree models are often used to solve **classification and regression problems**. A decision tree in machine learning is a predictive model that represents a **mapping between object attributes and object values**, with **each node in the tree representing a judgement condition for an object attribute** and its **branches representing the objects for which the symbolic node conditions**. The **leaf nodes of the tree represent the predicted outcomes to which the objects belong**.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Decision Tree\n",
    "\n",
    "> Binary Decision Tree\n",
    "> Non-Binary Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}