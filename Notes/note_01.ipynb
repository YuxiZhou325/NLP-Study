{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Note 01 for NLP Study\n",
    "**Author: Yuxi Zhou** <br>\n",
    "Start from: 2021-10-04 21:01:50"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Note about the time stamp: </h2>\n",
    "\n",
    "*Settings - Live Template* <br>\n",
    "[Tutorial of Quick Insert Time](https://www.hhtjim.com/the-idea-of-quick-insert-the-current-time.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Machine Learning: Overfitting and Underfitting</h2>\n",
    "\n",
    "[Overfitting and Underfitting With Machine Learning Algorithms](https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/)\n",
    "\n",
    "<h3>Overfitting in Machine Learning </h3>\n",
    "\n",
    "> Overfitting refers to a model that **training data too well**.\n",
    ">\n",
    "> Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model. The problem is that these concepts do not apply to new data and negatively impact the models ability to generalize.\n",
    ">\n",
    "> Overfitting is more likely with nonparametric and nonlinear models that have more flexibility when learning a target function. As such, many nonparametric machine learning algorithms also include parameters or techniques to limit and constrain how much detail the model learns.\n",
    ">\n",
    "> For example, decision trees are a nonparametric machine learning algorithm that is very flexible and is subject to overfitting training data. This problem can be addressed by pruning a tree after it has learned in order to remove some of the detail it has picked up.\n",
    "\n",
    "\n",
    "<h3>Underfitting in Machine Learning</h3>\n",
    "\n",
    "> Underfitting refers to a model that **can neither model the training data nor generalize to new data**.\n",
    ">\n",
    "> An underfitting machine learning model is not a suitable model and will be obvious as it will have poor performance on the training data.\n",
    ">\n",
    "> Underfitting is often not discussed as it is easy to detect given a good performance metric. The remedy is to move on and try alternate machine learning algorithms. Nevertheless, it does provide a good contrast to the problem of overfitting.\n",
    ">\n",
    "> Underfitting occurs when a **model is too simple** — informed by too few features or regularized too much — which makes it inflexible in learning from the dataset. Simple learners tend to have less variance in their predictions but more bias towards wrong outcomes.\n",
    "\n",
    "<h3>How do you know if you are Overfitting or Underfitting?</h3>\n",
    "\n",
    "> - **Overfitting** is when the model's error on the training set (i.e. during training) is very low but then, the model's error on the test set (i.e. unseen samples) is large <br> (**Low train error, High test error**)\n",
    ">\n",
    "> - **Underfitting** is when the model's error on both the training and test sets (i.e. during training and testing) is very high <br> (**High train error, High test error**)\n",
    "\n",
    "<h3>How do I fix Underfitting problems</h3>\n",
    "\n",
    "> Below are a few techniques that can be used to reduce Underfitting:\n",
    ">\n",
    "> 1. Decrease regularization. Regularization is typically used to reduce the variance with a model by applying a penalty to the input parameters with the larger coefficients.\n",
    "> 2. Increase the duration of training.\n",
    "> 3. Feature selection.\n",
    "\n",
    "<h3>How do I fix Overfitting problems</h3>\n",
    "\n",
    "> Below are a few techniques that can be used to reduce Overfitting:\n",
    ">\n",
    "> 1. **Reduce the network’s capacity** by removing layers or reducing the number of elements in the hidden layers\n",
    "> 2. Apply **regularization**, which comes down to adding a cost to the loss function for large weights\n",
    "> 3. Use **Dropout layers**, which will randomly remove certain features by setting them to zero\n",
    "\n",
    "<h3>Regularization</h3>\n",
    "\n",
    "Regularization is a technique used for tuning the function by adding an additional penalty term in the error function. The additional term controls the excessively fluctuating function such that the coefficients don't take extreme values.\n",
    "\n",
    "L1 regularization gives output in binary weights from 0 to 1 for the model's features and is adopted for decreasing the number of features in a huge dimensional dataset.\n",
    "\n",
    "L2 regularization disperse the error terms in all the weights that leads to more accurate customized final models.\n",
    "\n",
    "<h2>Regularization in Logistic Regression</h2>\n",
    "\n",
    "- [Does Regularization in Logistic Regression Always Results in Better Fit and Better Generalization](https://sebastianraschka.com/faq/docs/regularized-logistic-regression-performance.html)\n",
    "> Now, if we regularize the cost function (e.g., via L2 regularization), we add an additional term to our cost function (J) that increases as the value of your parameter weights (w) increase; keep in mind that the regularization we add a new hyperparameter, lambda, to control the regularization strength.\n",
    "\n",
    "\n",
    "\n",
    "- [Overfitting vs. Underfitting](https://towardsdatascience.com/overfitting-vs-underfitting-a-complete-example-d05dd7e19765)\n",
    "- [Underfitting and Overfitting in machine learning and how to deal with it](https://towardsdatascience.com/underfitting-and-overfitting-in-machine-learning-and-how-to-deal-with-it-6fe4a8a49dbf#:~:text=Underfitting%20occurs%20when%20a%20model,more%20bias%20towards%20wrong%20outcomes.)\n",
    "- [Is your model overfitting? Or maybe underfitting?](https://towardsdatascience.com/is-your-model-overfitting-or-maybe-underfitting-an-example-using-a-neural-network-in-python-4faf155398d2)\n",
    "- [Techniques that can Reduce Underfitting](https://www.ibm.com/cloud/learn/underfitting)\n",
    "\n",
    "<h2>Bias and Variance</h2>\n",
    "\n",
    "- [Bias/Variance and Model Selection](http://www.cs.cornell.edu/courses/cs4780/2015fa/web/lecturenotes/lecturenote13.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[StackOverflow: Can't instantiate abstract class with abstract methods](https://stackoverflow.com/questions/31457855/cant-instantiate-abstract-class-with-abstract-methods)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>How to deal with Structure Data</h2>\n",
    "\n",
    "<h3>Categorical Data</h3>\n",
    "\n",
    ">There are many ways to encode categorical data\n",
    ">\n",
    "> - **Integer Encoding**: Each unique label is mapped to an integer (but raise the problem of \"1\" are readed as more important than \"0\")\n",
    "> - **OneHot Encoding**: Each label is mapped to a binary vector\n",
    "> - **Learned Embedding**: A distributed representation of the categories is learned."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Structured Data vs Unstructured Data</h2>\n",
    "\n",
    "<h3>Structured Data</h3> | <h3>Unstructured Data</h3>\n",
    "--- | ---\n",
    "Structured data is quantitative and is often displayed as **numbers**, **dates**, **values**, and **strings** | Unstructured data is qualitative data and includes **text**, **video**, **audio**, **images**, and more\n",
    "Structured data is stored in **rows and columns** | Unstructured data is stored as **text**, **audio** and **video files**, or **NoSQL databases**.\n",
    "Stored in **data warehouses** | Stored in **applications**, **NoSQL (non-relational) databases**, **data lakes**, and **data warehouses**.\n",
    "Easy to analyze with tools like Excel | Hard to analyze without AI tools\n",
    "\n",
    " - [Structure vs. Unstructured Data](https://monkeylearn.com/blog/structured-data-vs-unstructured-data/)\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Python Set Doc String</h2>\n",
    "\n",
    "- [StackOverflow: Set Docstring](https://stackoverflow.com/questions/4056983/how-do-i-programmatically-set-the-docstring)\n",
    "- [Docstrings in Python](https://www.datacamp.com/community/tutorials/docstrings-python)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Python pip list freeze</h2>\n",
    "\n",
    "- [How to install Python packages with pip and requirements.txt](https://note.nkmk.me/en/python-pip-list-freeze/)\n",
    "> $ pip freeze > requirements.txt\n",
    ">\n",
    "> $ pip install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Data Structure: well suited to efficiently implement a Priority Queue</h2>\n",
    "\n",
    "- [Priority Queue](https://algs4.cs.princeton.edu/24pq/#:~:text=The%20binary%20heap%20is%20a,at%20two%20other%20specific%20positions.)\n",
    "- [Google Search Results](https://www.google.com/search?q=which+data+structure+is+well+suited+to+efficiently+implement+a+priority+queue&oq=which+data+structure+is+well+suited+to+efficiently+implement+a+priority+queue&aqs=chrome..69i57j0i512.14033j0j7&sourceid=chrome&ie=UTF-8)\n",
    "\n",
    "**The binary heap** is a data structure that can efficiently support the basic priority-queue operations. In a binary heap, the items are stored in an array such that each key is guaranteed to be larger than (or equal to) the keys at two other specific positions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Solving Maze as Represented in ASCII</h2>\n",
    "\n",
    "- [Google Search Results](https://www.google.com/search?q=suppose+you+need+to+wirte+a+program+to+solve+a+maze+as+represented+in+ASCII&oq=suppose+you+need+to+wirte+a+program+to+solve+a+maze+as+represented+in+ASCII&aqs=chrome..69i57j0i13.26368j0j7&sourceid=chrome&ie=UTF-8)\n",
    "- [Graphs - Solving a Maze](https://inginious.org/course/competitive-programming/graphs-maze)\n",
    "- [Google Search Results: Priority Queue Solving Maze](https://www.google.com/search?q=priority+queue+soving+maze&oq=priority+queue+soving+maze&aqs=chrome..69i57j33i10i160l3.11043j0j7&sourceid=chrome&ie=UTF-8)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Greedy Algorithm</h2>\n",
    "\n",
    "- [Google Search Results](https://www.google.com/search?q=example+of+greedy+algorithm&oq=example+of+greedy+algorithm&aqs=chrome..69i57j0i512j0i20i263i512j0i22i30l5j0i390.14051j0j7&sourceid=chrome&ie=UTF-8)\n",
    "\n",
    ">Is Dijkstra a Greedy Algorithm? <br>\n",
    "Yes. It is a greedy algorithm that solves the single-source the shortest path problem for a directed graph.\n",
    "\n",
    "**Top 7 Greedy Algorithm Problems**\n",
    "- Activity Selection Problem.\n",
    "- Graph Coloring Problem.\n",
    "- Job Sequencing Problem with Deadlines.\n",
    "- Find minimum platforms needed to avoid delay in the train arrival.\n",
    "- Huffman Coding Compression Algorithm.\n",
    "- Single-Source Shortest Paths — Dijkstra's Algorithm.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Priority Queue</h2>\n",
    "\n",
    "- [Priority Queue using Linked List](https://www.geeksforgeeks.org/priority-queue-using-linked-list/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Array Sorting</h2>\n",
    "\n",
    "- [Sort an almost sorted array where only two elements are swapped](https://www.geeksforgeeks.org/sort-an-almost-sorted-array-where-only-two-elements-are-swapped/)\n",
    "- [What is the best sorting algorithm for an almost sorted array?](https://www.educative.io/edpresso/what-is-the-best-sorting-algorithm-for-an-almost-sorted-array)\n",
    "- [Sorting Algorithms: Slowest to Fastest with Time Complexity](https://medium.com/javarevisited/sorting-algorithms-slowest-to-fastest-a9f0e30937b9)\n",
    "\n",
    "> What does it mean for a sorting algorithm to be stable? <br>\n",
    "> A sorting algorithm is stable if it **preserves the order of duplicate keys** <br>\n",
    "> Reference: [Stable Sorting Algorithms](https://cs.smu.ca/~porter/csc/common_341_342/notes/sorts_stable.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Hash Table: Bucket</h2>\n",
    "\n",
    "- [StackOverflow: Hashtable stores multiple items with same hash in one bucket](https://stackoverflow.com/questions/26287852/java-hashtable-stores-multiple-items-with-same-hash-in-one-bucket)\n",
    "\n",
    "**Problem Description**\n",
    ">While reading Oracle documentation about Hashtable I found that \"in the case of a \"**hash collision**\", a single bucket stores multiple entries, which must be searched sequentially\", so I try to find method which will return me items sequentially, if I have two items with the same hash, but can't find in the documentation. In order to reproduce this situation I try to write a simple code, which you can find below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Asymptotically Tight Bound</h2>\n",
    "\n",
    "[Big-θ (Big-Theta) Notation](https://www.khanacademy.org/computing/computer-science/algorithms/asymptotic-notation/a/big-big-theta-notation)\n",
    ">When we use **big-Θ notation**, we're saying that we have an asymptotically tight bound on the running time. \"Asymptotically\" because it matters for only large values of n. \"Tight bound\" because we've nailed the running time to within a constant factor above and below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Find Unique Array Element</h2>\n",
    "\n",
    "- [Problem to find unique array element](https://codepumpkin.com/find-unique-array-element/)\n",
    "\n",
    "    l = [0, 0, 1, 0, 0, 1, 1, 1, 2, 2, 3, 2, 3]\n",
    "\n",
    "\n",
    "    def counter(list):\n",
    "        # parse the list and find occurance\n",
    "        count = dict()\n",
    "        for item in list:\n",
    "            if item in count:\n",
    "                count[item] += 1\n",
    "            else:\n",
    "                count[item] = 1\n",
    "        return count\n",
    "\n",
    "\n",
    "    print(counter(l))\n",
    "\n",
    "    # an alternative way just for fun\n",
    "    result = {\n",
    "        0: l.count(0),\n",
    "        1: l.count(1),\n",
    "        2: l.count(2),\n",
    "        3: l.count(3)\n",
    "    }\n",
    "    print(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Logarithm Time Multiplication Table</h2>\n",
    "\n",
    "\n",
    "- [Google Search Results](https://www.google.com/search?q=python+logarithm+time+multiplication+table&sxsrf=AOaemvKZ6f1EKTxbZB3YzLupljEqtEx75A%3A1633018724391&ei=ZONVYZ6zF4zAgweH0oeIBw&oq=python+logarithm+time+multiplication+table&gs_lcp=Cgdnd3Mtd2l6EAM6BwgAEEcQsANKBAhBGABQ-IcBWM-0AWC8twFoAXACeACAAe8CiAGDGZIBAzMtOZgBAKABAcgBCMABAQ&sclient=gws-wiz&ved=0ahUKEwie9ennjKfzAhUM4OAKHQfpAXEQ4dUDCA4&uact=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Data Structures: Questions</h2>\n",
    "\n",
    ">[Which data structure is used in redo-undo feature?](https://www.geeksforgeeks.org/data-structures-misc-question-1/) <br>\n",
    ">Answer: **Stack** <br>\n",
    ">Explanation: Stack data structure is most suitable to implement redo-undo feature. This is because the stack is implemented with LIFO(last in first out) order which is equivalent to redo-undo feature i.e. the last re-do is undo first."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Machine Learning: The Goal of Cross Validation</h2>\n",
    "\n",
    "> The purpose of cross–validation is to **test the ability of a machine learning model to predict new data**. It is also used to flag problems like overfitting or selection bias and gives insights on how the model will generalize to an independent dataset. <br>\n",
    "> Reference: [What is Cross Validation in Machine Learning](https://www.mygreatlearning.com/blog/cross-validation/#:~:text=The%20purpose%20of%20cross%E2%80%93validation,generalize%20to%20an%20independent%20dataset.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Logarithm Transformation in Linear Regression Models</h2>\n",
    "\n",
    "> Problem: <br>\n",
    "> Taking the logarithm of a feature before performing regression is most beneficial when that feature...\n",
    ">\n",
    "> [Logarithmic Transformation in Linear Regression Models: Why & When](https://dev.to/rokaandy/logarithmic-transformation-in-linear-regression-models-why-when-3a7c)\n",
    ">\n",
    "> Using the logarithm of one or more variables improves the fit of the model by **transforming the distribution of the features to a more normally-shaped bell curve**.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Linear Algebra: Projection onto a Subspace</h2>\n",
    "\n",
    "> [Real Euclidean Vector Spaces](https://www.cliffsnotes.com/study-guides/algebra/linear-algebra/real-euclidean-vector-spaces/projection-onto-a-subspace)\n",
    ">\n",
    "> Problem: Orthogonal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Recommender System</h2>\n",
    "\n",
    "> [Collaborative Filtering](https://en.wikipedia.org/wiki/Collaborative_filtering)\n",
    ">\n",
    "> The system generates recommendations using only information about rating profiles for different users or items. By locating peer users/items with a rating history similar to the current user or item, they generate recommendations using this neighborhood. Collaborative filtering methods are classified as memory-based and model-based. A well-known example of memory-based approaches is the user-based algorithm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Resample Time Series Data</h2>\n",
    "\n",
    "> Question: Reason for resample time series data\n",
    ">\n",
    "> [How To Resample and Interpolate Your Time Series Data With Python](https://machinelearningmastery.com/resample-interpolate-time-series-data-python/#:~:text=There%20are%20perhaps%20two%20main,you%20want%20to%20make%20predictions.) <br>\n",
    "> There are perhaps two main reasons why you may be interested in resampling your time series data: <br>\n",
    "> 1. **Problem Framing**:  Resampling may be required if your data is not available at the same frequency that you want to make predictions.\n",
    "> 2. **Feature Engineering**: Resampling can also be used to provide additional structure or insight into the learning problem for supervised learning models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Note about Markdown Syntax</h2>\n",
    "\n",
    "- [Basic Syntax](https://www.markdownguide.org/basic-syntax/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Machine Learning Models: Labelled Data</h2>\n",
    "\n",
    "> Does AutoEncoder need labelled data? <br>\n",
    "> AutoEncoders are considered an unsupervised learning technique since they don't need explicit labels to train on. But to be more precise they are self-supervised because they generate their own labels from the training data.\n",
    ">\n",
    "> KNN is a **Supervised Learning Algorithm** <br>\n",
    "> A supervised machine learning algorithm is one that relies on labelled input data to learn a function that produces an appropriate output when given unlabeled data. ... That is supervised learning. When we substitute the child with a computer, it becomes supervised machine learning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>N-grams Query for Auto-complete</h2>\n",
    "\n",
    "- [Implementing Auto-complete in Elasticsearch: N-grams](https://www.learningstuffwithankit.dev/implementing-auto-complete-functionality-in-elasticsearch-part-ii-n-grams)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Mean, Variance and Standard Deviation</h2>\n",
    "\n",
    "> Whether mean or variance streaming dataset too large to fit in memory\n",
    "> - [Streaming Mean and Variance Computation](http://www.nowozin.net/sebastian/blog/streaming-mean-and-variance-computation.html)\n",
    "> - [StackOverflow: Calculating mean and standard deviation](https://stackoverflow.com/questions/1174984/how-to-efficiently-calculate-a-running-standard-deviation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Gradient Boosting Tree vs. Random Forest</h2>\n",
    "\n",
    "- [StackOverflow: Gradient boosting tree vs random forest](https://stats.stackexchange.com/questions/173390/gradient-boosting-tree-vs-random-forest)\n",
    "> error = bias + variance\n",
    ">\n",
    "> - Boosting is based on **weak** learners (high bias, low variance). In terms of decision trees, weak learners are shallow trees, sometimes even as small as decision stumps (trees with two leaves). Boosting reduces error mainly by reducing bias (and also to some extent variance, by aggregating the output from many models).\n",
    "> - On the other hand, Random Forest uses as you said **fully grown decision trees** (low bias, high variance). It tackles the error reduction task in the opposite way: by reducing variance. The trees are made uncorrelated to maximize the decrease in variance, but the algorithm cannot reduce bias (which is slightly higher than the bias of an individual tree in the forest). Hence the need for large, unpruned trees, so that the bias is initially as low as possible.\n",
    ">\n",
    "> Please note that unlike Boosting (which is sequential), RF grows trees in **parallel**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>CNN Provides Invariance to Mirroring</h2>\n",
    "\n",
    "> Is CNN an invariant?\n",
    ">\n",
    "> [Are CNNs invariant to translation, rotation, and scaling?](https://www.pyimagesearch.com/2021/05/14/are-cnns-invariant-to-translation-rotation-and-scaling/)\n",
    ">\n",
    "> Unless your training data includes digits that are rotated across the full 360-degree spectrum, your **CNN is not truly rotation invariant**. ... Therefore, CNNs can be seen as “not caring” exactly where an activation fires, simply that it does fire — and, in this way, we naturally handle translation inside a CNN.\n",
    "\n",
    "> [About CNN, kernels and scale/rotation invariance](https://stats.stackexchange.com/questions/239076/about-cnn-kernels-and-scale-rotation-invariance)\n",
    ">\n",
    ">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Gradient Descent</h2>\n",
    "\n",
    "<h3>Possible reasons for Gradient Decent not reach Global Minima</h3>\n",
    "\n",
    "> [Does gradient descent always converge to an optimum?](https://datascience.stackexchange.com/questions/24534/does-gradient-descent-always-converge-to-an-optimum)\n",
    "> \n",
    "> Gradient Descent need not always converge at global minimum. It all depends on following conditions; If the line segment between any two points on the graph of the function lies above or on the graph then it is convex function.\n",
    ">\n",
    "> Gradient Descent is an iterative process that finds the minima of a function. This is an optimisation algorithm that finds the parameters or coefficients of a function where the function has a minimum value. Although this function does not always guarantee to find a global minimum and can get stuck at a local minimum.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}